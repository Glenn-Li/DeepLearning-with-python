{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b852187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入Python包，在jupyter notebook 运行后可以直接输出多个变量 注意大小写\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# 指定gpu设备\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] =\"0\" # gpu\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283380a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Miniconda3\\envs\\tensorflow_114_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Miniconda3\\envs\\tensorflow_114_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Miniconda3\\envs\\tensorflow_114_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Miniconda3\\envs\\tensorflow_114_gpu\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "\n",
    "model = load_model('cats_and_dogs_small_vgg16_02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df70d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0037d05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 30\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights ' \n",
    "         'before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16c9af17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x00000145CAB66548> vgg16\n",
      "<keras.layers.core.Flatten object at 0x00000145CAE94988> flatten_1\n",
      "<keras.layers.core.Dense object at 0x00000145CAE6ABC8> dense_1\n",
      "<keras.layers.core.Dense object at 0x00000145CAF0CB88> dense_2\n"
     ]
    }
   ],
   "source": [
    "# 冻结vgg16卷积基\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.name)\n",
    "    if layer.name == 'vgg16':\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba4a4bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights ' \n",
    "         'before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "615d4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = 'kaggle-dogs-vs-cats/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b108ee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array,array_to_img\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 验证数据不能增强\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d980b27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 214s 2s/step - loss: 0.2867 - acc: 0.8755 - val_loss: 0.3019 - val_acc: 0.9030\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 414s 4s/step - loss: 0.2745 - acc: 0.8820 - val_loss: 0.3028 - val_acc: 0.8990\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 387s 4s/step - loss: 0.2764 - acc: 0.8815 - val_loss: 0.2692 - val_acc: 0.9000\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 257s 3s/step - loss: 0.2678 - acc: 0.8870 - val_loss: 0.1856 - val_acc: 0.9020\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 177s 2s/step - loss: 0.2711 - acc: 0.8830 - val_loss: 0.6089 - val_acc: 0.8920\n"
     ]
    }
   ],
   "source": [
    "# 编译器要在设置 model.trainable = False 之后再配置\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                                    steps_per_epoch=100,\n",
    "                                    epochs=5,\n",
    "                                    validation_data=validation_generator,\n",
    "                                    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6456ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory( \n",
    "        test_dir, \n",
    "        target_size=(150, 150), \n",
    "        batch_size=20, \n",
    "        class_mode='binary')\n",
    "model.evaluate_generator(test_generator, steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1) \n",
    " \n",
    "plt.plot(epochs, acc, 'bo', label='Training acc') \n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc') \n",
    "plt.title('Training and validation accuracy') \n",
    "plt.legend() \n",
    " \n",
    "plt.figure() \n",
    " \n",
    "plt.plot(epochs, loss, 'bo', label='Training loss') \n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss') \n",
    "plt.title('Training and validation loss') \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_vgg16_03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9751efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a45df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_114_gpu]",
   "language": "python",
   "name": "conda-env-tensorflow_114_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
